{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330406e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_org='../SentenceGeneration/Data/DebiasingCorpus/Original/corpus_1-13_20k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f393fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sim='../SentenceGeneration/Data/DebiasingCorpus/CDA/corpus_1-13_20k.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5008dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bidhanbashyal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Downloading necessary NLTK data\n",
    "\n",
    "def calculate_total_tokens_and_ngrams(sentences):\n",
    "    total_tokens = 0\n",
    "    unique_tokens = set()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenizing the sentence\n",
    "        tokens = word_tokenize(sentence)\n",
    "        total_tokens += len(tokens)\n",
    "\n",
    "        # Updating the set of unique tokens\n",
    "        unique_tokens.update(tokens)\n",
    "\n",
    "    total_unique_tokens = len(unique_tokens)\n",
    "\n",
    "    return total_tokens/len(sentences), total_unique_tokens/len(sentences)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d3acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_sentences = []\n",
    "with open(path_sim, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Strip to remove any leading/trailing whitespace\n",
    "        sentence = line.strip()\n",
    "        # Only add non-empty sentences\n",
    "        if sentence:\n",
    "            same_sentences.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639adede",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_sentences = []\n",
    "with open(path_org, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Strip to remove any leading/trailing whitespace\n",
    "        sentence = line.strip()\n",
    "        # Only add non-empty sentences\n",
    "        if sentence:\n",
    "            org_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f947f431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Saif's lack of follow-up left me feeling frustrated and neglected, and I was left to wonder if he was truly invested in the project or if he had simply lost interest.\",\n",
       " \"Saif 's lack of follow-up left me feeling frustrated and neglected , and I was left to wonder if she was truly invested in the project or if she had simply lost interest .\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcadc3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saif never followed up; nor did i.', 'saif never followed up ; nor did i .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde2f7c",
   "metadata": {},
   "source": [
    "## Checking number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841c10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens per sentence: 44.5568\n"
     ]
    }
   ],
   "source": [
    "average_tokens, total_bigrams =  calculate_total_tokens_and_ngrams(same_sentences)\n",
    "print(f\"Average number of tokens per sentence: {average_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c8a611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens per sentence: 11.65025\n"
     ]
    }
   ],
   "source": [
    "average_tokens, total_bigrams =  calculate_total_tokens_and_ngrams(org_sentences)\n",
    "print(f\"Average number of tokens per sentence: {average_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f117ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(same_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e70d4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(org_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc0d62",
   "metadata": {},
   "source": [
    "## Checking similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f23d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of sentence 1: 0.0714933109839\n",
      "Similarity of sentence 2: 0.0714933109839\n",
      "Similarity of sentence 3: 0.04247934487912242\n",
      "Similarity of sentence 4: 0.04247934487912242\n",
      "Similarity of sentence 5: 0.16439003964172438\n",
      "Similarity of sentence 6: 0.16439003964172438\n",
      "Similarity of sentence 7: 0.2571561571248326\n",
      "Similarity of sentence 8: 0.2571561571248326\n",
      "Similarity of sentence 9: 0.45062382369775605\n",
      "Similarity of sentence 10: 0.45062382369775605\n",
      "Similarity of sentence 11: 0.18435554192630063\n",
      "Similarity of sentence 12: 0.18435554192630063\n",
      "Similarity of sentence 13: 0.11726076605993337\n",
      "Similarity of sentence 14: 0.11726076605993337\n",
      "Similarity of sentence 15: 0.05040125896780564\n",
      "Similarity of sentence 16: 0.05040125896780564\n",
      "Similarity of sentence 17: 0.3232354058650929\n",
      "Similarity of sentence 18: 0.3232354058650929\n",
      "Similarity of sentence 19: 0.25557297390468403\n",
      "Similarity of sentence 20: 0.25557297390468403\n",
      "Similarity of sentence 21: 0.07980011014729993\n",
      "Similarity of sentence 22: 0.07980011014729993\n",
      "Similarity of sentence 23: 0.16066317813277575\n",
      "Similarity of sentence 24: 0.16066317813277575\n",
      "Similarity of sentence 25: 0.31869581309511913\n",
      "Similarity of sentence 26: 0.31869581309511913\n",
      "Similarity of sentence 27: 0.23415216117099885\n",
      "Similarity of sentence 28: 0.23415216117099885\n",
      "Similarity of sentence 29: 0.11346926790227241\n",
      "Similarity of sentence 30: 0.11346926790227241\n",
      "Similarity of sentence 31: 0.1530397804744767\n",
      "Similarity of sentence 32: 0.1530397804744767\n",
      "Similarity of sentence 33: 0.0606962227082572\n",
      "Similarity of sentence 34: 0.0606962227082572\n",
      "Similarity of sentence 35: 0.3185467146861102\n",
      "Similarity of sentence 36: 0.3185467146861102\n",
      "Similarity of sentence 37: 0.18326047070942206\n",
      "Similarity of sentence 38: 0.18326047070942206\n",
      "Similarity of sentence 39: 0.08866908822481674\n",
      "Similarity of sentence 40: 0.08866908822481674\n",
      "Similarity of sentence 41: 0.17879967536077768\n",
      "Similarity of sentence 42: 0.17879967536077768\n",
      "Similarity of sentence 43: 0.2526501417257641\n",
      "Similarity of sentence 44: 0.24554430703795663\n",
      "Similarity of sentence 45: 0.3248951654660034\n",
      "Similarity of sentence 46: 0.27028495739253056\n",
      "Similarity of sentence 47: 0.4665431338716407\n",
      "Similarity of sentence 48: 0.4665431338716407\n",
      "Similarity of sentence 49: 0.1988850846585267\n",
      "Similarity of sentence 50: 0.1988850846585267\n",
      "Similarity of sentence 51: 0.11891969394359321\n",
      "Similarity of sentence 52: 0.11891969394359321\n",
      "Similarity of sentence 53: 0.16476021401706162\n",
      "Similarity of sentence 54: 0.15931714012918272\n",
      "Similarity of sentence 55: 0.15557430832379307\n",
      "Similarity of sentence 56: 0.15557430832379307\n",
      "Similarity of sentence 57: 0.37461455132091515\n",
      "Similarity of sentence 58: 0.37461455132091515\n",
      "Similarity of sentence 59: 0.1724324501705497\n",
      "Similarity of sentence 60: 0.1724324501705497\n",
      "Similarity of sentence 61: 0.2325824517313352\n",
      "Similarity of sentence 62: 0.2325824517313352\n",
      "Similarity of sentence 63: 0.22502131124694102\n",
      "Similarity of sentence 64: 0.22502131124694102\n",
      "Similarity of sentence 65: 0.06114721862044751\n",
      "Similarity of sentence 66: 0.06114721862044751\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m total_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(org_sentences), \u001b[38;5;28mlen\u001b[39m(same_sentences))):\n\u001b[0;32m----> 9\u001b[0m     tfidf_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform([org_sentences[i], same_sentences[i]])\n\u001b[1;32m     10\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], tfidf_matrix[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity of sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:2126\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2121\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2122\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2123\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2124\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2125\u001b[0m )\n\u001b[0;32m-> 2126\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2128\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1383\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1376\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1377\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1378\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m             )\n\u001b[1;32m   1381\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1386\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1289\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1291\u001b[0m         )\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "l=[]\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "total_similarity = 0\n",
    "for i in range(min(len(org_sentences), len(same_sentences))):\n",
    "    tfidf_matrix = vectorizer.fit_transform([org_sentences[i], same_sentences[i]])\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    print(f\"Similarity of sentence {i+1}: {similarity[0][0]}\")\n",
    "    total_similarity += similarity[0][0]\n",
    "\n",
    "average_similarity = total_similarity / min(len(org_sentences), len(same_sentences))\n",
    "print(f\"Average Similarity: {average_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a80c88",
   "metadata": {},
   "source": [
    "## Checking text token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aba22306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ttr(sentences_list):\n",
    "    ttr_per_sentence = []\n",
    "    types_=[]\n",
    "    for sentence in sentences_list:\n",
    "        tokens = sentence.split()\n",
    "        types = len(set(tokens))\n",
    "        tokens_total = len(tokens)\n",
    "        ttr = types / tokens_total if tokens_total > 0 else 0\n",
    "        ttr_per_sentence.append(ttr)\n",
    "        types_.append(tokens_total)\n",
    "    average_ttr = sum(ttr_per_sentence) / len(ttr_per_sentence) if len(ttr_per_sentence) > 0 else 0\n",
    "    avg_types=sum(types_)/len(types_)\n",
    "    print(avg_types)\n",
    "    final_score=average_ttr-(1/avg_types)\n",
    "    return ttr_per_sentence, average_ttr,final_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9229605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.65945\n",
      "42.34315\n",
      "Text-to-token ratio for list1(Original Sentence): 0.98\n",
      "Text-to-token ratio for list2(generated Sentence): 0.82\n",
      "0.8842110461558006\n",
      "0.799501837633001\n"
     ]
    }
   ],
   "source": [
    "_,ratio_list1,f1 = calculate_ttr(org_sentences)\n",
    "_,ratio_list2,f2 = calculate_ttr(same_sentences)\n",
    "\n",
    "print(f\"Text-to-token ratio for list1(Original Sentence): {ratio_list1:.2f}\")\n",
    "print(f\"Text-to-token ratio for list2(generated Sentence): {ratio_list2:.2f}\")\n",
    "print(f1)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eccaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hapax_legomenon_ratio(sentences_list):\n",
    "    def get_word_tokens(sentences):\n",
    "        tokens = []\n",
    "        for sentence in sentences:\n",
    "            # Split each sentence into words\n",
    "            words = sentence.split()\n",
    "            tokens.extend(words)\n",
    "        return tokens\n",
    "\n",
    "    # Get word tokens from the given list\n",
    "    tokens = get_word_tokens(sentences_list)\n",
    "\n",
    "    # Calculate the number of hapax legomena (words occurring only once)\n",
    "    hapax_legomena = [word for word in set(tokens) if tokens.count(word) == 1]\n",
    "\n",
    "    # Calculate the hapax legomenon ratio (HLR)\n",
    "    hlr = len(hapax_legomena) / len(tokens) if len(tokens) > 0 else 0\n",
    "\n",
    "    return hlr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22cfa49",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ratio_list1 \u001b[38;5;241m=\u001b[39m calculate_hapax_legomenon_ratio(org_sentences)\n\u001b[1;32m      2\u001b[0m ratio_list2 \u001b[38;5;241m=\u001b[39m calculate_hapax_legomenon_ratio(same_sentences)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText-to-token ratio for list1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mratio_list1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mcalculate_hapax_legomenon_ratio\u001b[0;34m(sentences_list)\u001b[0m\n\u001b[1;32m     11\u001b[0m tokens \u001b[38;5;241m=\u001b[39m get_word_tokens(sentences_list)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the number of hapax legomena (words occurring only once)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m hapax_legomena \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(tokens) \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mcount(word) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the hapax legomenon ratio (HLR)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m hlr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(hapax_legomena) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m tokens \u001b[38;5;241m=\u001b[39m get_word_tokens(sentences_list)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the number of hapax legomena (words occurring only once)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m hapax_legomena \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(tokens) \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mcount(word) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the hapax legomenon ratio (HLR)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m hlr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(hapax_legomena) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ratio_list1 = calculate_hapax_legomenon_ratio(org_sentences)\n",
    "ratio_list2 = calculate_hapax_legomenon_ratio(same_sentences)\n",
    "\n",
    "print(f\"Text-to-token ratio for list1: {ratio_list1:.2f}\")\n",
    "print(f\"Text-to-token ratio for list2: {ratio_list2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca507424",
   "metadata": {},
   "source": [
    "## Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c968b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "def calculate_readability_scores(sentences):\n",
    "    # Join the list of sentences into a single text\n",
    "    text = ' '.join(sentences)\n",
    "\n",
    "    # Calculate readability scores\n",
    "    flesch_kincaid = textstat.flesch_kincaid_grade(text)\n",
    "    gunning_fog = textstat.gunning_fog(text)\n",
    "\n",
    "    return flesch_kincaid, gunning_fog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63775130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 19.4\n",
      "Gunning Fog Index: 15.61\n"
     ]
    }
   ],
   "source": [
    "flesch_kincaid_score, gunning_fog_score = calculate_readability_scores(same_sentences)\n",
    "\n",
    "print(f\"Flesch-Kincaid Grade Level: {flesch_kincaid_score}\")\n",
    "print(f\"Gunning Fog Index: {gunning_fog_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d4f2d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 6.0\n",
      "Gunning Fog Index: 4.61\n"
     ]
    }
   ],
   "source": [
    "flesch_kincaid_score, gunning_fog_score = calculate_readability_scores(org_sentences)\n",
    "\n",
    "print(f\"Flesch-Kincaid Grade Level: {flesch_kincaid_score}\")\n",
    "print(f\"Gunning Fog Index: {gunning_fog_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82abec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
