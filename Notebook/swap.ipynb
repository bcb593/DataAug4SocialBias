{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe68fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373da11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus='../SentenceGeneration/Data/DebiasingCorpus/Generated/corpus_1-13_10k.txt'\n",
    "path_male='../SentenceGeneration/Data/gender_wordlist/man_word_list.txt'\n",
    "path_female='../SentenceGeneration/Data/gender_wordlist/woman_word_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a536fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with open(path_corpus, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip()\n",
    "        if sentence:\n",
    "            corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b47a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = []\n",
    "with open(path_male, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip()\n",
    "        if sentence:\n",
    "            male_words.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49327c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_words = []\n",
    "with open(path_female, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        sentence = line.strip()\n",
    "        if sentence:\n",
    "            female_words.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "954148e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8db53fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_balancing_cda(corpus, male_words, female_words, p=0.5):\n",
    "    augmented_corpus = []\n",
    "    augmented_only=[]\n",
    "    tt=[]\n",
    "    for idx, sentence in enumerate(corpus):\n",
    "        tokens = word_tokenize(sentence)\n",
    "        augmented_tokens = []\n",
    "\n",
    "        for token in tokens:\n",
    "            # Replace gender-specific words with counterparts based on the same index\n",
    "            if token.lower() in male_words:\n",
    "                #print(token)\n",
    "                tt.append(token)\n",
    "                female_equivalent = female_words[male_words.index(token.lower())]\n",
    "                augmented_tokens.append(female_equivalent)\n",
    "            elif token.lower() in female_words:\n",
    "                #print(token)\n",
    "                tt.append(token)\n",
    "                male_equivalent = male_words[female_words.index(token.lower())]\n",
    "                augmented_tokens.append(male_equivalent)\n",
    "            else:\n",
    "                augmented_tokens.append(token)\n",
    "           \n",
    "        augmented_sentence = \" \".join(augmented_tokens)\n",
    "        augmented_corpus.append(sentence)\n",
    "        augmented_corpus.append(augmented_sentence)\n",
    "        augmented_only.append(augmented_sentence)\n",
    "        \n",
    "    return augmented_corpus,augmented_only,tt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d066fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_corpus,a,t = gender_balancing_cda(corpus, male_words, female_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203d933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../SentenceGeneration/Data/DebiasingCorpus/Generated/corpus_1-13_10kCDA.txt', 'w') as file:\n",
    "    for item in a:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cfa7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../SentenceGeneration/Data/DebiasingCorpus/CDA/corpus_1-13_20k.txt', 'w') as file:\n",
    "    for item in augmented_corpus:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4bf435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\tOriginal Sentence\tAugmented Sentence\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print the original and corrected augmented corpus with indices\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mOriginal Sentence\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mAugmented Sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, original_sentence, augmented_sentence \u001b[38;5;129;01min\u001b[39;00m augmented_corpus:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moriginal_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00maugmented_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the original and corrected augmented corpus with indices\n",
    "print(\"Index\\tOriginal Sentence\\tAugmented Sentence\")\n",
    "for idx, original_sentence, augmented_sentence in augmented_corpus:\n",
    "    print(f\"{idx}\\t{original_sentence}\\t{augmented_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa70dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
